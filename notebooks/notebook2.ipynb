{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ECIR 2021 Tutorial Notebook - Part 2.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"562458b5bd6d4bb3a629932a2edc54d7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_224e088c2ac64cc29b1d78a5e850ebe4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3cc8a8231dc44c768dffbc755dd0f2fb","IPY_MODEL_d998ea1d78fa458d94e3107bc2a514b5"]}},"224e088c2ac64cc29b1d78a5e850ebe4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3cc8a8231dc44c768dffbc755dd0f2fb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ae5b4e71f7a74bb8aaa7c8bf1e985993","_dom_classes":[],"description":"cord19/trec-covid documents: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":192509,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":192509,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_587cc3f3700b4201b750e8fd3408e34d"}},"d998ea1d78fa458d94e3107bc2a514b5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c6b946af922e4b248a5bfecd99e11a8c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 192509/192509 [06:11&lt;00:00, 518.22it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_eb34c2ee16c241ea955bb088632f603d"}},"ae5b4e71f7a74bb8aaa7c8bf1e985993":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"587cc3f3700b4201b750e8fd3408e34d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c6b946af922e4b248a5bfecd99e11a8c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"eb34c2ee16c241ea955bb088632f603d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"0Oe730o8rzyn"},"source":["# PyTerrier ECIR 2021 Tutorial Notebook - Part 2\n","\n","This notebook provides experiences to attendees for building transformer pipelines in [PyTerrier](https://github.com/terrier-org/pyterrier). All experiments are conducted using the [CORD19 corpus](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7251955/) and the [TREC Covid test collection](https://ir.nist.gov/covidSubmit/).\n","\n","This notebook is divided in two, following the structure of the slides. In particular, in Part 2A you will experience: \n"," - understand the PyTerrier data model;\n"," - understand the general notion of PyTerrier transformers and operators for combining transformers into new transformers;\n"," - undertake experiments on the TREC Covid test collection.\n","\n","In Part 2B, you will experience:\n"," - construct and learn learning-to-rank pipelines;\n"," - evaluate and analyse learning-to-rank pipelines.\n"]},{"cell_type":"markdown","metadata":{"id":"0edvI3LDtOym"},"source":["# Setup\n","\n","We install PyTerrier, as well as the [LightGBM](https://lightgbm.readthedocs.io/en/latest/) and [FastRank](https://github.com/jjfiv/fastrank) learning-to-rank implementations, and we will initialise PyTerrier."]},{"cell_type":"code","metadata":{"id":"mkCdrWdRzS64","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616668024544,"user_tz":-60,"elapsed":34696,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}},"outputId":"c6770726-25a2-4971-b1e6-6fb44efb4f83"},"source":["!pip install --upgrade fastrank lightgbm \n","!pip install python-terrier"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SWc4UQgX6vDD","executionInfo":{"status":"ok","timestamp":1616668027562,"user_tz":-60,"elapsed":37396,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}},"outputId":"30cd0f3d-aafe-428f-eaa4-9163de61d4af"},"source":["import pyterrier as pt\n","if not pt.started():\n","  pt.init()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p18d1tpJvD_5"},"source":["# Indexing\n","\n","We're going to create a new index for Cord19. In this index, we use the `blocks=True` argument, so that we have position information in the index.\n","Indexing takes ~1 minute."]},{"cell_type":"code","metadata":{"id":"C9E6oLubIeI4","colab":{"base_uri":"https://localhost:8080/","height":239,"referenced_widgets":["562458b5bd6d4bb3a629932a2edc54d7","224e088c2ac64cc29b1d78a5e850ebe4","3cc8a8231dc44c768dffbc755dd0f2fb","d998ea1d78fa458d94e3107bc2a514b5","ae5b4e71f7a74bb8aaa7c8bf1e985993","587cc3f3700b4201b750e8fd3408e34d","c6b946af922e4b248a5bfecd99e11a8c","eb34c2ee16c241ea955bb088632f603d"]},"executionInfo":{"status":"ok","timestamp":1616668163381,"user_tz":-60,"elapsed":135816,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}},"outputId":"0170a2d2-169e-4377-c538-a335efd8dec8"},"source":["import os\n","\n","cord19 = pt.datasets.get_dataset('irds:cord19/trec-covid')\n","pt_index_path = './terrier_cord19_blocks'\n","\n","if not os.path.exists(pt_index_path + \"/data.properties\"):\n","    # create the index, using the IterDictIndexer indexer \n","    indexer = pt.index.IterDictIndexer(pt_index_path, blocks=True)\n","\n","    # we give the dataset get_corpus_iter() directly to the indexer\n","    # while specifying the fields to index and the metadata to record\n","    index_ref = indexer.index(cord19.get_corpus_iter(), \n","                              fields=('abstract',), \n","                              meta=('docno',))\n","\n","else:\n","    # if you already have the index, use it.\n","    index_ref = pt.IndexRef.of(pt_index_path + \"/data.properties\")\n","\n","index = pt.IndexFactory.of(index_ref)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OiM8I_fkUcQ9"},"source":["## Transformers & Operators\n","\n","You'll have noted that BatchRetrieve has a `transform()` method that takes as input a dataframe, and returns another dataframe, which is somehow a *transformation* of the earlier dataframe (e.g., a retrieval transformation). In fact, `BatchRetrieve` is just one of many similar objects in PyTerrier, which we call [transformers](https://pyterrier.readthedocs.io/en/latest/transformer.html) (represented by the `TransformerBase` class).\n","\n","Let's give a look at a `BatchRetrieve` transformer, starting with one for the TF_IDF weighting model."]},{"cell_type":"code","metadata":{"id":"UqMt-9UlTqLa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616668164873,"user_tz":-60,"elapsed":554,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}},"outputId":"96e17d34-c984-418d-b087-24302b758e15"},"source":["tfidf = pt.BatchRetrieve(index, wmodel=\"TF_IDF\")\n","\n","# check tfidf is a transformer...\n","print(isinstance(tfidf, pt.transformer.TransformerBase))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lAR09Eff7lUE","executionInfo":{"status":"ok","timestamp":1616668164873,"user_tz":-60,"elapsed":552,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}},"outputId":"29ef5fda-c3af-492b-b5d9-87cbcbe8813f"},"source":["# this prints the type hierarchy of the TF_IDF class\n","tfidf.__class__.__mro__"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GW3afDgPukvU"},"source":["The interesting capability of all transformers is that they can be combined using Python operators (this is called *operator overloading*).\n","\n","Concretely, imagine that you want to chain transformers together – e.g. rank documents first by Tf then re-ranked the *exact same* documents by TF_IDF. We can do this using the `>>` operator – we call this *composition*, or \"*then*\"."]},{"cell_type":"code","metadata":{"id":"e9HkXxtgug15","colab":{"base_uri":"https://localhost:8080/","height":470},"executionInfo":{"status":"ok","timestamp":1616668219672,"user_tz":-60,"elapsed":1823,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}},"outputId":"6bdd961d-4ff2-4b17-ffb6-6bbc6a42670a"},"source":["# this is our first retrieval transformer\n","# it transform a queries dataframe to a results dataframe\n","tf = pt.BatchRetrieve(index, wmodel=\"Tf\")\n","\n","tf( cord19.get_topics(variant='title').head(1) )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uHHIn-rMvk_5","colab":{"base_uri":"https://localhost:8080/","height":453},"executionInfo":{"status":"ok","timestamp":1616668229117,"user_tz":-60,"elapsed":878,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}},"outputId":"2060c226-bbea-46db-e0a8-57f0086fc3d6"},"source":["# now let's define a pipeline \n","pipeline = tf >> tfidf\n","print(isinstance(tfidf, pt.transformer.TransformerBase))\n","\n","pipeline( cord19.get_topics(variant='title').head(1) )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r1yCXIB5w1Qb"},"source":["There are a number of PyTerrier operators – there are more examples in the [PyTerrier documentation on operators](https://pyterrier.readthedocs.io/en/latest/operators.html)"]},{"cell_type":"markdown","metadata":{"id":"NaYavGvnxDk5"},"source":["## Practice Task – Pipeline Construction\n","\n","Create a ranker that performs the follinwg:\n"," - obtains the top 10 highest scoring documents by term frequency (`wmodel=\"Tf\"`)\n"," - obtains the top 10 highest scoring documents by TF.IDF (`wmodel=\"TF_IDF\"`)\n"," - reranks only those documents found in BOTH of the previous retrieval settings using BM25.\n","\n","How many documents are retrieved by this full pipeline for the query `\"chemical\"`.\n","> If you obtain the correct solution, the document with docno `\"37771\"` should have a score of $12.426309\t$ for query `\"chemical\"`.\n","\n","Hints:\n"," - choose careully your [PyTerrier operators](https://pyterrier.readthedocs.io/en/latest/operators.html)\n"," - you should not need to perform any Pandas dataframe operations"]},{"cell_type":"code","metadata":{"id":"XnsRdT4WvspD","executionInfo":{"status":"ok","timestamp":1616668361281,"user_tz":-60,"elapsed":634,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}}},"source":["# SOLUTION\n","\n","pipe = (tfidf %10) & (tf %10)\n","pipe = pipe >>  pt.BatchRetrieve(index, wmodel=\"BM25\")\n","pipe.search(\"chemical\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4g8V7Zzpy3g1"},"source":["## Other transformers in the toolbox\n","\n","Lets start creating more interesting retrieval pipelines. We'll define these, but firstly lets recap on the PyTerrier datamodel:\n"," - $Q$: a set of queries\n"," - $D$: a set of documents\n"," - $R$: a set of retrieved documents for a set of queries\n","\n","Lets use three: \n"," - `pt.BatchRetrieve(index, wmodel=\"BM25\")` - input $Q$ or $R$ (retrieval or reranking), output $R$\n"," - `pt.rewrite.SDM()` (sequential dependence proximity model) - input $Q$, output $Q$. \n"," - `pt.rewrite.Bo1QueryExpansion(index)` - input $R$, output $Q$.\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"5nJHxh7A2dPP","executionInfo":{"status":"ok","timestamp":1616668415043,"user_tz":-60,"elapsed":720,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}}},"source":["bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")\n","sdm = pt.rewrite.SDM()\n","qe = pt.rewrite.Bo1QueryExpansion(index)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IVmde7NpJdTT"},"source":["## Practice Task – Experimenting with Pipelines\n","\n","Conduct an [Experiment](https://pyterrier.readthedocs.io/en/latest/experiments.html) comparing sequential dependence model and Bo1 query expansion on TREC CORD19 with the BM25 baseline. You will need to construct appropriate pipelines, by consdering the input and output datatypes of the `bm25`, `sdm` and `qe`. \n","\n","Which approaches result in significant increases in NDCG and MAP? Is NDCG@10 also improved?"]},{"cell_type":"code","metadata":{"id":"TF24TZSb3bOo","executionInfo":{"status":"ok","timestamp":1616668451894,"user_tz":-60,"elapsed":927,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}}},"source":["topics = cord19.get_topics(variant='title')\n","qrels = cord19.get_qrels()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eqXox-g-JpUd","executionInfo":{"status":"ok","timestamp":1616668453463,"user_tz":-60,"elapsed":648,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}}},"source":["# SOLUTION\n","sdm_pipe = sdm >> bm25\n","qe_pipe = bm25 >> qe >> bm25"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":142},"id":"8IX0UXwXJcyD","executionInfo":{"status":"ok","timestamp":1616668472521,"user_tz":-60,"elapsed":18294,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}},"outputId":"954e63e1-0724-4ec2-92f6-62f8231a8108"},"source":["# SOLUTION\n","pt.Experiment(\n","    [bm25, sdm_pipe, qe_pipe],\n","    topics,\n","    qrels,\n","    names=[\"BM25\", \"BM25 + SDM\", \"BM25 + QE\"],\n","    baseline=0,\n","    eval_metrics=[\"map\", \"ndcg\", \"ndcg_cut_10\"])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0aJrYP1TSLwY"},"source":["# Part 2B – Learning to Rank\n","\n","In this part of the notebook, you will experience constructing, learning, evaluating and analysing learning to rank pipelines.\n"]},{"cell_type":"markdown","metadata":{"id":"CSi3svV24mCs"},"source":["Firstly, lets split out topics into train, validation and test sets. TREC Covid only has 50 topics, which isnt a lot for learning(!). We'll split this 35 for training, 5 for validation and 15 for evaluation. We will also examine statistical significance, even if this is artificial for 15 topics.\n","\n","We're only going to-rank the top 10 documents for each query - hopefully learning to rank can help to re-rank the top 10 documents to be more effective."]},{"cell_type":"code","metadata":{"id":"INvVKQz6K7SB","executionInfo":{"status":"ok","timestamp":1616668500768,"user_tz":-60,"elapsed":889,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}}},"source":["RANK_CUTOFF = 10\n","SEED=42\n","\n","from sklearn.model_selection import train_test_split\n","\n","tr_va_topics, test_topics = train_test_split(topics, test_size=15, random_state=SEED)\n","train_topics, valid_topics =  train_test_split(tr_va_topics, test_size=5, random_state=SEED)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vftc_y-65VfA"},"source":["## Feature Set\n","\n","Lets define our feature set.  We're going to have a total of 7 features:\n","\n","1.   the BM25 abstract score;\n","2.   sequential dependence model, scored by BM25;\n","3.   does the abstract contain 'coronavirus covid', scored by BM25;\n","4.   the BM25 score on the title (even though we didnt index it earlier!);\n","5.   was the paper released/published in 2020? Recent papers were more useful for this task;\n","6.   does the paper have a DOI, i.e. is it a formal publication?\n","7.   the coordinate match score for the query - i.e. how many query terms appear in the abstract.\n","\n","Several of these feature require additional metadata `[\"title\", \"date\", \"doi\"]`. Fortunately, the TREC Covid dataset allows us to obtain more metadata after indexing. We use `pt.text.get_text(cord19, [\"title\", \"date\", \"doi\"])` to retrieve these extra metadata columns.\n"]},{"cell_type":"code","metadata":{"id":"AYgwwrsPTGP1","executionInfo":{"status":"ok","timestamp":1616668557695,"user_tz":-60,"elapsed":634,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}}},"source":["ltr_feats1 = (bm25 % RANK_CUTOFF) >> pt.text.get_text(cord19, [\"title\", \"date\", \"doi\"])  >> (\n","    pt.transformer.IdentityTransformer()\n","    ** #sequential dependence\n","    sdm_pipe\n","    ** # score of text for query 'coronavirus covid'\n","    (pt.apply.query(lambda row: 'coronavirus covid') >> bm25)\n","    ** # score of title (not originally indexed)\n","    (pt.text.scorer(body_attr=\"title\", takes='docs', wmodel='BM25') ) \n","    ** #date 2020\n","    (pt.apply.doc_score(lambda row: int(\"2020\" in row[\"date\"])))\n","    ** #has doi\n","    (pt.apply.doc_score(lambda row: int( row[\"doi\"] is not None and len(row[\"doi\"]) > 0) ))\n","    ** #abstract coordinate match\n","    pt.BatchRetrieve(index, wmodel=\"CoordinateMatch\")\n",")\n","\n","# for reference, lets record the feature names here too\n","fnames=[\"BM25\", \"SDM\", 'coronavirus covid', 'title', \"2020\", \"hasDoi\", \"CoordinateMatch\"]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nu3M9ujw6trC"},"source":["Lets see the output for a particular query. We can see that we now have extra document metadata columns `[\"title\", \"date\", \"doi\"]`, as well as the all-important `\"features\"` columns. This makes dataframe have type $R_f$. Indeed,  it is this column that we use for learning."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":359},"id":"OMG9kK9AUWI4","executionInfo":{"status":"ok","timestamp":1616668567796,"user_tz":-60,"elapsed":1000,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}},"outputId":"e4f6cbf8-4e89-46c8-b6c7-8d3e75eac2f3"},"source":["ltr_feats1.search(\"coronovirus origin\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3vQNbSSgJCmC"},"source":["We can also look at the raw features values (in this case for the first ranked document). Note that the BM25 in the \"score\" column above is also the first value in the feature array (20.54), because we used an identity transformer."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EzVDLL8pI_gR","executionInfo":{"status":"ok","timestamp":1616668573072,"user_tz":-60,"elapsed":1006,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}},"outputId":"ff60a8d3-ebc0-4d1b-b87d-0e6245ad7553"},"source":["ltr_feats1.search(\"coronovirus origin\").iloc[0][\"features\"]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Od8P-N4E7QTk"},"source":["## Learning \n","\n","In this part of the the notebook, we apply three different learning to rank techniques:\n","\n"," - coordinate ascent from FastRank, a listwise linear technique\n"," - random forests from `scikit-learn`, a pointwise regression tree technique\n"," - LambdaMART from LightGBM, a listwise regression tree technique\n","\n","In each case, we take our feature pipeline, `ltr_feats1`, and we compose it (`>>`) with the learned model. We use `pt.ltr.apply_learned_model()` which knows how to deal with different learners.\n","\n","The full pipeline is then fitted (learned) using `.fit()`, specifying the training topics and qrels. Importantly, the preceeding stages of the pipeline (retrieval and feature calculation) are applied to the training topics in order to obtained the results, which are then passed to the learning to rank technique. LightGBM has early stopping enabled, which uses a validation topics set – similarly the validation topics are transformed into validation results.\n","\n","Finally, `%time` is notebook \"magic command\" which displays how long learning takes for each technique. Learning for each technique takes < 30 seconds."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OFPZ39eSYIXV","executionInfo":{"status":"ok","timestamp":1616668669944,"user_tz":-60,"elapsed":23178,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}},"outputId":"0c3e398c-ae14-4fce-8d94-703151d53ad0"},"source":["import fastrank\n","\n","train_request = fastrank.TrainRequest.coordinate_ascent()\n","\n","params = train_request.params\n","params.init_random = True\n","params.normalize = True\n","params.seed = 1234567\n","\n","ca_pipe = ltr_feats1 >> pt.ltr.apply_learned_model(train_request, form='fastrank')\n","\n","%time ca_pipe.fit(train_topics, cord19.get_qrels())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T0SpZ13wUagq","executionInfo":{"status":"ok","timestamp":1616668679862,"user_tz":-60,"elapsed":9897,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}},"outputId":"c3fdfa85-bad7-47d0-b95b-f51ba9d35efb"},"source":["from sklearn.ensemble import RandomForestRegressor\n","\n","rf = RandomForestRegressor(n_estimators=400, verbose=1, random_state=SEED, n_jobs=2)\n","\n","rf_pipe = ltr_feats1 >> pt.ltr.apply_learned_model(rf)\n","\n","%time rf_pipe.fit(train_topics, cord19.get_qrels())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u0jb1jw_VdWU","executionInfo":{"status":"ok","timestamp":1616668695125,"user_tz":-60,"elapsed":8930,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}},"outputId":"1d658e08-07d7-4753-cc79-a987ebafc6ee"},"source":["import lightgbm as lgb\n","\n","# this configures LightGBM as LambdaMART\n","lmart_l = lgb.LGBMRanker(\n","    task=\"train\",\n","    silent=False,\n","    min_data_in_leaf=1,\n","    min_sum_hessian_in_leaf=1,\n","    max_bin=255,\n","    num_leaves=31,\n","    objective=\"lambdarank\",\n","    metric=\"ndcg\",\n","    ndcg_eval_at=[10],\n","    ndcg_at=[10],\n","    eval_at=[10],\n","    learning_rate= .1,\n","    importance_type=\"gain\",\n","    num_iterations=100,\n","    early_stopping_rounds=5\n",")\n","\n","max_depth=5, #was unlimited\n","num_leaves=16, #was 31\n","min_gain_to_split=0.1, #was 0\n","min_sum_hessian_in_leaf=100,\n","min_data_in_leaf=2, #was 1\n","\n","lmart_x_pipe = ltr_feats1 >> pt.ltr.apply_learned_model(lmart_l, form=\"ltr\", fit_kwargs={'eval_at':[10]})\n","\n","%time lmart_x_pipe.fit(train_topics, cord19.get_qrels(), valid_topics, cord19.get_qrels())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b7rNqB7sBKFB"},"source":["## Evaluation\n","\n","Lets now compare our ranking pipelines on our 15 topics with the BM25 baseline. In all cases, we're ranking only 10 results per query, so MAP will be lower. \n","\n","We'll report mean response time (`\"mrt\"`) as well as MAP, NDCG and NDCG@10 measures."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":241},"id":"P0EhTwejVqev","executionInfo":{"status":"ok","timestamp":1616668732099,"user_tz":-60,"elapsed":8964,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}},"outputId":"3393cb4e-2a2e-4e92-ede5-5857457ca863"},"source":["pt.Experiment(\n","    [bm25 % RANK_CUTOFF, ca_pipe, rf_pipe, lmart_x_pipe],\n","    test_topics,\n","    qrels, \n","    names=[\"BM25\",  \"BM25 + CA(7f)\", \"BM25 + RF(7f)\", \"BM25 + LMart(7f)\"],\n","    baseline=0,\n","    eval_metrics=[\"map\", \"ndcg\", \"ndcg_cut_10\", \"mrt\"])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LmGe5rniC_Pn"},"source":["Thats really interesting – all three learned models could improve NDCG@10 over BM25, but the coordinate ascent model improved the most (significantly so on all three metrics, but again on only 15 queries). Coordinate Ascent improved upto 11 queries."]},{"source":["## Analysis\n","\n","Lets start to analyse our learned models. Two things we could do is either a feature ablation study, or to evaluate the performance of each feature independently. To to that, we compose the feature pipeline (`ltr_feats1`) with `pt.ltr.feature_to_score(i)` for some feature number $i$."],"cell_type":"markdown","metadata":{"id":"4ov0JjWGEbrT"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":266},"id":"7nCb9U7uvszV","executionInfo":{"status":"ok","timestamp":1616668775186,"user_tz":-60,"elapsed":17063,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}},"outputId":"ea79739f-9155-4343-9f7d-62a5d523ebcd"},"source":["pt.Experiment(\n","    [ltr_feats1 >> pt.ltr.feature_to_score(i) for i in range(len(fnames))],\n","    test_topics,\n","    qrels, \n","    names=fnames,\n","    eval_metrics=[\"map\", \"ndcg\", \"ndcg_cut_10\", \"num_rel_ret\"])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rU7YYKFSFeke"},"source":["Interesting, we observe that the 'coronavirus covid' feature achieved NDCG@10 of 0.572172. On average, this outperforms some of the regression tree-based learners. That coordinate ascent could outperform the strongest feature gives some credence to the appropriateness of such a linear learner in  environments without lots of training data."]},{"cell_type":"markdown","metadata":{"id":"VjaWBEo8HA20"},"source":["Next, we analyse the actual learned models. For the coordinate ascent model, we plot the feature weights (note the log-scale y-axis); while for the regression-tree based techniques, we report the feature importance."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":464},"id":"CdOP1b8Cjp44","executionInfo":{"status":"ok","timestamp":1616668777541,"user_tz":-60,"elapsed":2333,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}},"outputId":"e2da7f44-21de-4fc0-a6f5-50c3285b6525"},"source":["import matplotlib.pyplot as plt, numpy as np\n","\n","fig, (ax0, ax1, ax2) = plt.subplots(1, 3, figsize=(10, 6))\n","\n","ax0.bar(np.arange(len(fnames)), ca_pipe[1].model.to_dict()['Linear']['weights'])\n","ax0.set_xticks(np.arange(len(fnames)))\n","ax0.set_xticklabels(fnames, rotation=45, ha='right')\n","ax0.set_title(\"Coordinate Ascent\\n Feature Weights\")\n","ax0.set_yscale('log')\n","\n","ax1.bar(np.arange(len(fnames)), rf.feature_importances_)\n","ax1.set_xticks(np.arange(len(fnames)))\n","ax1.set_xticklabels(fnames, rotation=45, ha='right')\n","ax1.set_title(\"Random Forests\\n Feature Importance\")\n","\n","ax2.bar(np.arange(len(fnames)), lmart_l.feature_importances_)\n","ax2.set_xticks(np.arange(len(fnames)))\n","ax2.set_xticklabels(fnames, rotation=45, ha='right')\n","ax2.set_title(\"$\\lambda$MART\\n Feature Importance\")\n","\n","fig.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1HhGDiPLHO7v"},"source":["## Practice Task – Concatenation\n","\n","Our learned model has low recall because only 10 documents are re-ranked. Lets make a small function, `append_baseline()`, that can append the BM25 baselines results to the output of the learned model. This is defined using [transformer operators](https://pyterrier.readthedocs.io/en/latest/operators.html) (`^` and `%`).\n","\n","As an exercise, apply `append_baseline()` to each of the learned model pipelines defined above, and report the MAP and NDCG computed on all 1000 ranked results. \n","\n","Which of the learned models result in significantly improved MAP and NDCG?\n"]},{"cell_type":"code","metadata":{"id":"yypYHpf-nX7w","executionInfo":{"status":"ok","timestamp":1616668782058,"user_tz":-60,"elapsed":693,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}}},"source":["def append_baseline(system, baseline, max_results = 1000):\n","    return (system ^ baseline) % max_results"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":241},"id":"4pvGYFJ1q-cJ","executionInfo":{"status":"ok","timestamp":1616668799792,"user_tz":-60,"elapsed":13229,"user":{"displayName":"Nicola Tonellotto","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gga8BaxLsPFWvzzBzSximki7T2Jsnf0EEARTd_h=s64","userId":"17533833776178224794"}},"outputId":"198bedd6-98f3-4e12-ab00-4ef8a5b16e9b"},"source":["# SOLUTION\n","pt.Experiment(\n","    [append_baseline(system, bm25) for system in [bm25 % RANK_CUTOFF, ca_pipe, rf_pipe, lmart_x_pipe]],\n","    test_topics,\n","    cord19.get_qrels(), \n","    names=[\"BM25\",  \"BM25 + CA(7f)\", \"BM25 + RF(7f)\", \"BM25 + LMart(7f)\"],\n","    baseline=0,\n","    eval_metrics=[\"num_ret\", \"map\", \"ndcg\", \"ndcg_cut_10\", \"mrt\"])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qLm3m_IXIIQG"},"source":["#  That's all folks\n","\n","If you arent coming back to Part 3 of the tutorial, please dont forget to complete our exit quiz: https://forms.office.com/r/2WbpLiQmWV"]}]}